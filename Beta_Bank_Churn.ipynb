{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba892046-0cae-47eb-93c3-5b6d5ec7633a",
   "metadata": {},
   "source": [
    "# Beta Bank Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb891626-e44a-40de-b943-449db9b85c3f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a76d1-9fce-46d1-94fc-231b04b4ffe6",
   "metadata": {},
   "source": [
    "I have data on Beta Bank customers, and my goal is to prediect whether not they will leave soon. My data includes contract termination status. To predict their behavior, I will try out a variety of supervised machine learning classifier models - logistic regression, decision tree, random forest. I'll look for duplicate rows and fill in missing values like usual. I'll split the data into feature and target sets. To train the logistic regression model, I will have to one-hot encode the categorical features and standardize the numeric features; for the tree/forest models, I will use ordinal encoding and numeric standardization. I will split both dataframes into training, validation, and test sets.\n",
    "\n",
    "I will examine the balance of classes in the target, and try building my models without balancing the classes, taking note of the F1 and accuracy scores. When I train my models, I will be optimizing for the highest possible F1 score, with accuracy as a sidenote.\n",
    "\n",
    "Then I will use downsampling and upsampling functions to balance the numbers of positive and negative target observations (the classes), train and validate the models with these fully preprocessed data sets, and select the model with the highest F1 score. At the end I will test the model's final F1 score using the testing set and find the AUC-ROC score. The primary requirement for a successful model is that the tested F1 score is at least 0.59. I will also do a sanity check on the accuracy and require the final tested model to surpass the accuracy score gleaned from chance, and the AUC-ROC will need to be over 0.50.\n",
    "\n",
    "Personally, I hope to gain greater understanding of how to preprocess data for different models, and how to balance classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f371db4-2ced-4c54-9913-7238e7cc2a0d",
   "metadata": {},
   "source": [
    "***Note to reviewer: using the enhanced performance package for Intel processors below, runtime was 25 seconds. When I ran the code without it, it took my laptop more than five minutes or so to finish running the code (I lost patience and stopped waiting). If the code doesn't run for you in a timely manner, I have an alternate model you can run that has the same hyperparameters and whatnot as what I found to be ideal. I hope that's OK.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47702530-3922-484e-966a-81de18c41011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d88f1ac-260e-47de-9db6-384f1417582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# from sklearnex import patch_sklearn # Enhanced performance package for Intel processors\n",
    "# patch_sklearn()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c436f-9e29-4b19-8ae2-69930b740d15",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93500f5-f529-4eec-9ad6-d9778ca1f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c23b628-aeb0-45c6-840e-5bc4e33b697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031dfa1-b002-43eb-83da-2c2f3a2bd69d",
   "metadata": {},
   "source": [
    "Almost 10% of the tenure data is missing. I don't want to drop these rows, but I should fill in the nans for the machine learning algorithms. Let's check normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1df937f-95ba-4e15-ae29-6e7d73073f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Tenure.hist(figsize=(4,2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060b09e-7908-4978-b07a-2df42977bfc7",
   "metadata": {},
   "source": [
    "The distribution is uniform, not normal. Though mean and median look like they will be about equal anyway. Let's just use the median to fill in values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76feeee8-a981-4ba8-bd95-49fbd5864fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Tenure = df.Tenure.fillna(df.Tenure.median()).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf52402-b706-4b66-9642-787709ea72d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1308bb0-c6f2-4cd5-842b-f3e3236313be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int32  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int32(1), int64(8), object(3)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f78a604e-9799-40a4-97b6-bbddf5e4cecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6093991-37c1-4ef6-96c6-0711249774b3",
   "metadata": {},
   "source": [
    "There are no duplicate rows, and missing values have been filled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469ab70-20dc-4d68-bd12-4fccece95d9a",
   "metadata": {},
   "source": [
    "I will process the dataframe using one-hot encoding for when we test our logistic regression model, and separately using ordinal encoding for when we test our decision tree and random forest classifier models. The categorical features, geography and gender, are both nominal, so we won't have to worry about assigning orders to them. Before that I will collect the features and targets into their own DataFrames/Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "031098c3-cab0-4136-bb27-81abad797e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['RowNumber', 'CustomerId', 'Surname', 'Exited'], axis=1) # Omit unhelpful features (identifiers) along with the target\n",
    "target = df.Exited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb46a3-0ffd-466c-9cdc-b1f3804c32c5",
   "metadata": {},
   "source": [
    "## Prepare logistic regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb57d34b-714a-4fab-8722-7cb27858e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ohe = pd.get_dummies(features, drop_first=True) # Create one-hot encoded dataframe for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef3468-66d9-4a7e-b60a-c0abdc5fd963",
   "metadata": {},
   "source": [
    "Now that we've dealt with the categorical variables, I'd like to standardize the numeric variables. We can use the standard scaler class for this. But, we'll need to split up the data into training, validation, and testing sets before I standardize the data, to make sure the class uses the most precise mean/variance for its calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732a0b3-0bd1-4002-82ca-07912395931f",
   "metadata": {},
   "source": [
    "I want 60% of the data to be used for training, and 20% for the validation and test sets each. \n",
    "We will first split the features and target datasets into a training set and a test set, at an 80/20 ratio. \n",
    "Then, we can further divide this new training set into an ultimate training set and a validation set. In this case, the validation set needs to come from 25% of the training set to give us the 60/20/20 ratio. This is because 25% of 80 equals 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "111266e3-485a-459b-a726-c9b6d9690108",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, features_test_ohe, y_train, target_test = train_test_split(\n",
    "    features_ohe, target, test_size=0.2, random_state=123)\n",
    "\n",
    "features_train_ohe, features_valid_ohe, target_train, target_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930e5fba-b383-49d9-8a72-2e822a556aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary'] # Create mask of numeric features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train_ohe[numeric])\n",
    "\n",
    "features_train_ohe[numeric] = scaler.transform(features_train_ohe[numeric])\n",
    "features_valid_ohe[numeric] = scaler.transform(features_valid_ohe[numeric])\n",
    "features_test_ohe[numeric] = scaler.transform(features_test_ohe[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d443693c-e796-402d-ab0f-ae091b605482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>0.652468</td>\n",
       "      <td>-1.698690</td>\n",
       "      <td>1.096509</td>\n",
       "      <td>-1.213083</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.535390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>0.886952</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.637287</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0.621526</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.258423</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.681465</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.698668</td>\n",
       "      <td>1.420312</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.672609</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.776236</td>\n",
       "      <td>1.703857</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>0.538309</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.715362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "8189     0.652468 -1.698690  1.096509 -1.213083       0.781092          1   \n",
       "8845     0.796864  0.002583 -1.450269  0.886952      -0.920634          1   \n",
       "1165     0.621526  0.947735  0.005033  1.258423       0.781092          0   \n",
       "1742    -0.698668  1.420312 -1.450269  0.022130      -0.920634          0   \n",
       "1139     0.776236  1.703857 -1.450269  0.538309      -0.920634          0   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "8189               0        -0.535390                  0                0   \n",
       "8845               1         1.637287                  1                0   \n",
       "1165               0         1.681465                  1                0   \n",
       "1742               0         0.672609                  1                0   \n",
       "1139               1        -1.715362                  0                1   \n",
       "\n",
       "      Gender_Male  \n",
       "8189            1  \n",
       "8845            0  \n",
       "1165            0  \n",
       "1742            0  \n",
       "1139            0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0274412-aa48-4786-84ee-71032cbe85ea",
   "metadata": {},
   "source": [
    "The table looks as it is supposed to. The nominal categorical features have been split into binary features, and the numeric features have been scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a75232-2f3e-454d-b07e-66598627dc20",
   "metadata": {},
   "source": [
    "## Prepare decision tree/random forest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9461c1-2299-4db9-891f-a50d57dbe110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5068.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>217.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5793.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3696.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender   Age  Tenure  Balance  NumOfProducts  \\\n",
       "0        228.0        0.0     0.0  24.0     2.0      0.0            0.0   \n",
       "1        217.0        2.0     0.0  23.0     1.0    743.0            0.0   \n",
       "2        111.0        0.0     0.0  24.0     8.0   5793.0            2.0   \n",
       "3        308.0        0.0     0.0  21.0     1.0      0.0            1.0   \n",
       "4        459.0        2.0     0.0  25.0     2.0   3696.0            0.0   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0        1.0             1.0           5068.0  \n",
       "1        0.0             1.0           5639.0  \n",
       "2        1.0             0.0           5707.0  \n",
       "3        0.0             0.0           4704.0  \n",
       "4        1.0             1.0           3925.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "features_ordinal = pd.DataFrame(encoder.fit_transform(features), columns=features.columns) # Create label encoded dataframe for decision trees\n",
    "features_ordinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed329043-70e0-4a95-bad1-076bad7f6c53",
   "metadata": {},
   "source": [
    "Here I will split up the dataset in the same manner as last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87927531-3097-43d8-8349-88fe5d776f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, features_test_ord, y_train, target_test = train_test_split(\n",
    "    features_ordinal, target, test_size=0.2, random_state=123)\n",
    "\n",
    "features_train_ord, features_valid_ord, target_train, target_valid = train_test_split(\n",
    "    x_train, y_train, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff805e-a4e8-4f5f-bfd1-04f301788f07",
   "metadata": {},
   "source": [
    "Let's standardize the numeric features. We will again fit the scaler to the training set, and use this scaler to scale the training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fee1aa3-0af3-439c-bf8d-51816441b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary'] # Create mask of numeric features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train_ord[numeric])\n",
    "\n",
    "features_train_ord[numeric] = scaler.transform(features_train_ord[numeric])\n",
    "features_valid_ord[numeric] = scaler.transform(features_valid_ord[numeric])\n",
    "features_test_ord[numeric] = scaler.transform(features_test_ord[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef8cb28-3a7e-4e8f-9c65-6bdb3b3dbabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>0.652823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.700024</td>\n",
       "      <td>1.096509</td>\n",
       "      <td>-0.950460</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.539820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>0.797391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>1.025270</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.629777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>0.621844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.948774</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.692765</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.670968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>-0.699922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.421774</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>-0.720451</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.776739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.705574</td>\n",
       "      <td>-1.450269</td>\n",
       "      <td>0.148889</td>\n",
       "      <td>-0.920634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.704923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender       Age    Tenure   Balance  \\\n",
       "8189     0.652823        0.0     1.0 -1.700024  1.096509 -0.950460   \n",
       "8845     0.797391        1.0     0.0  0.002775 -1.450269  1.025270   \n",
       "1165     0.621844        1.0     0.0  0.948774  0.005033  1.692765   \n",
       "1742    -0.699922        1.0     0.0  1.421774 -1.450269 -0.720451   \n",
       "1139     0.776739        2.0     0.0  1.705574 -1.450269  0.148889   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "8189       0.781092        1.0             0.0        -0.539820  \n",
       "8845      -0.920634        1.0             1.0         1.629777  \n",
       "1165       0.781092        0.0             0.0         1.670968  \n",
       "1742      -0.920634        0.0             0.0         0.681011  \n",
       "1139      -0.920634        0.0             1.0        -1.704923  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_ord.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf4e921-95ce-49c7-998d-317f75233b93",
   "metadata": {},
   "source": [
    "The table looks as it is supposed to. The nominal categorical features have been turned into encoded into numbers, and the numeric features have been standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f2d1e0-9c1b-46d5-b183-933d1266171d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Train models without balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6dd70-c5d9-4af0-b2e5-0e8bc322a3a3",
   "metadata": {},
   "source": [
    "We can look at the target Series to see the balance between positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3606fc36-9ac7-427c-9dee-724895984d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_classes = target.value_counts()\n",
    "print(target_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0011e642-4717-4c65-904e-c89d8e3c6208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7963 of the target observations are negative.\n"
     ]
    }
   ],
   "source": [
    "class_ratio = target_classes[0]/target_classes.sum() #Perform sanity check\n",
    "print(class_ratio, 'of the target observations are negative.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cabb17-395b-45e3-a931-c54e30824f9a",
   "metadata": {},
   "source": [
    "Looks like there are far more negative target observations than positive ones. We'll try to balance this later, but for now we will train some models. This will help us to see the importance of class balance. We will evaluate models based on accuracy (must be at least 80% accurate, per sanity check), and ultimately on highest F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2009b559-2818-4d14-8989-80203b65f695",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6c2c11a-7dae-4609-b868-5b9bf9d3e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set: 0.30597014925373134\n",
      "Accuracy for training set: 0.814\n",
      "F1 score for validation set: 0.2783882783882784\n",
      "Accuracy for validation set: 0.803\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=123) # Using liblinear for small dataset\n",
    "model.fit(features_train_ohe, target_train)\n",
    "\n",
    "pred_train = model.predict(features_train_ohe)\n",
    "f1_score_train = f1_score(target_train, pred_train)\n",
    "accuracy_train = accuracy_score(target_train, pred_train)\n",
    "\n",
    "print('F1 score for training set:', f1_score_train)\n",
    "print('Accuracy for training set:', accuracy_train)\n",
    "\n",
    "pred_valid = model.predict(features_valid_ohe)\n",
    "f1_score_valid = f1_score(target_valid, pred_valid)\n",
    "accuracy_valid = accuracy_score(target_valid, pred_valid)\n",
    "\n",
    "print('F1 score for validation set:', f1_score_valid)\n",
    "print('Accuracy for validation set:', accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca191fb8-7623-4523-839d-5f9c156fb0da",
   "metadata": {},
   "source": [
    "The logistic regression model performed more poorly with regards to its F1 score than I expected. The lower F1 score for the validation set may indicate some overfitting. The accuracy is just above the 0.80 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942866e-3bba-4e3e-aabd-f53d96220b8b",
   "metadata": {},
   "source": [
    "## Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20903e3a-8651-4da6-9048-05664feb09a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.5393586005830905 obtained using max depth 8.\n",
      "Model accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "model_accuracy = 0\n",
    "best_f1_score = 0\n",
    "model_tree = None\n",
    "\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state = 123) # create instance of class\n",
    "    model.fit(features_train_ord, target_train) # Fit model with training data\n",
    "    pred_valid = model.predict(features_valid_ord)\n",
    "    \n",
    "    f1_score_var = f1_score(target_valid, pred_valid) # Calculate f1 score\n",
    "    accuracy = accuracy_score(target_valid, pred_valid)\n",
    "\n",
    "    # Document the highest-performing hyperparamaters, along with their corresponding accuracy\n",
    "    if f1_score_var > best_f1_score: \n",
    "        best_f1_score = f1_score_var\n",
    "        model_accuracy = accuracy\n",
    "        best_depth = depth\n",
    "        model_tree = model\n",
    "        \n",
    "print(f'Best F1 score: {best_f1_score} obtained using max depth {best_depth}.') \n",
    "print(f'Model accuracy: {model_accuracy}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5290697-5796-4487-a4fe-3e7e804d89fd",
   "metadata": {},
   "source": [
    "Using a decision tree, the f1 score is a bit shy of the requirement, but its accuracy is above the requirement. Let's try the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519408c-a4ce-4fcc-b95f-9cea057fe7d2",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2c059da-6d33-43a6-89a7-ba37d7ca6193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.5674418604651164 obtained using 60 trees with max_depth 8.\n",
      "Model accuracy: 0.8605\n"
     ]
    }
   ],
   "source": [
    "best_f1_score = 0\n",
    "model_accuracy = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "model_forest = None\n",
    "\n",
    "for est in range (10, 101, 10):\n",
    "    for depth in range (1, 11):\n",
    "        model = RandomForestClassifier(\n",
    "            max_features=1.0, # The lack of this hyperparameter was causing warnings.\n",
    "            n_estimators=est, max_depth=depth, random_state=123)\n",
    "        model.fit(features_train_ord, target_train)\n",
    "        pred_valid = model.predict(features_valid_ord)\n",
    "        \n",
    "        f1_score_var = f1_score(target_valid, pred_valid) # Calculate f1 score\n",
    "        accuracy = accuracy_score(target_valid, pred_valid)\n",
    "        \n",
    "        if f1_score_var > best_f1_score: \n",
    "            best_f1_score = f1_score_var\n",
    "            model_accuracy = accuracy\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "            model_tree = model\n",
    "            \n",
    "print(f\"Best F1 score: {best_f1_score} obtained using {best_est} trees with\\\n",
    " max_depth {best_depth}.\")\n",
    "print(f'Model accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d112d02-6e14-498b-b984-5d67f8c2e1be",
   "metadata": {},
   "source": [
    "The random forest model performs a bit better in terms of F1 score than the single decision tree. However it still has not reached the requirement of 0.59. The accuracy is still above the 0.80 cutoff. Let's try logistic regression, using the OHE features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9caf1e-974b-467f-b140-2593e99a8342",
   "metadata": {},
   "source": [
    "The model with the top F1 score is currently the random forest classifier with an F1 score of 0.56, which is nearly at our requirement of 0.59. Balancing the classes should be able to improve the F1 score for this model sufficiently. I am also curious to see what improvements, if any, are made to the logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4093b57-959b-47c7-bf42-a4dfa61ffe52",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Balance classes and retrain models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9990f971-da42-49d9-91cf-834ec7b06c74",
   "metadata": {},
   "source": [
    "Below I will input upsampling and downsampling functions that I can use when I balance the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ab626fe-fdcb-4c39-b9e4-298e0cdaf0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat): # Upsamples the positive class\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=54321)\n",
    "\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60d99cd1-7fcf-4445-8cc1-11629e30ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction): # Downsamples the negative class\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=54321)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=54321)] + [target_ones])\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=54321)\n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af93812-b53c-4c7e-ba1d-547aed9aee1c",
   "metadata": {},
   "source": [
    "## Logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893c61a-4d70-4e71-9933-9d88ad839470",
   "metadata": {},
   "source": [
    "Let's balance the classes by both downsampling a bit and by upsampling, first focusing on the logistic regression datasets. My goal for this model is for the classes to be evenly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f35b98-33a4-4c34-a7ed-eee68bedc3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4804, 11)\n",
      "(4804,)\n",
      "1    2406\n",
      "0    2398\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_train_ohe_downsampled, target_train_downsampled = downsample(features_train_ohe, target_train, 0.5)\n",
    "features_train_ohe_balanced, target_train_balanced = upsample(features_train_ohe_downsampled, target_train_downsampled, 2)\n",
    "\n",
    "print(features_train_ohe_balanced.shape)\n",
    "print(target_train_balanced.shape)\n",
    "print(target_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5001be-6352-4bf9-87a7-b1a992f97148",
   "metadata": {},
   "source": [
    "The classes have been balanced evenly through a combination of downsampling and upsampling. The two sets have the same length, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4cb1b7-6d11-4f0e-ade3-d9eb35bf569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for training set: 0.4860253015592822\n",
      "Accuracy for training set: 0.7088333333333333\n",
      "\n",
      "F1 score for validation set: 0.49871904355251917\n",
      "Accuracy for validation set: 0.7065\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=123) # Using liblinear for small dataset\n",
    "model.fit(features_train_ohe_balanced, target_train_balanced)\n",
    "\n",
    "pred_train = model.predict(features_train_ohe)\n",
    "f1_score_train = f1_score(target_train, pred_train)\n",
    "accuracy_train = accuracy_score(target_train, pred_train)\n",
    "\n",
    "print('F1 score for training set:', f1_score_train)\n",
    "print('Accuracy for training set:', accuracy_train)\n",
    "print()\n",
    "\n",
    "pred_valid = model.predict(features_valid_ohe)\n",
    "f1_score_valid = f1_score(target_valid, pred_valid)\n",
    "accuracy_valid = accuracy_score(target_valid, pred_valid)\n",
    "\n",
    "print('F1 score for validation set:', f1_score_valid)\n",
    "print('Accuracy for validation set:', accuracy_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234b2e8-4541-4ac8-9862-6d4af8155eae",
   "metadata": {},
   "source": [
    "The validation F1 score is a good bit higher than it was when the classes were unbalanced, though still a good bit below the requirement. The accuracy score also dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039c470-28b1-4d3f-a763-cf6e46cde83e",
   "metadata": {},
   "source": [
    "## Decision tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e679c-332e-4a7c-89ec-76bd730f3a8e",
   "metadata": {},
   "source": [
    "Now I will balance the datasets with ordinal labels in the same ratio as I did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10fd7e01-4811-4df0-9997-bbdc1df3e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4804, 10)\n",
      "(4804,)\n",
      "1    2406\n",
      "0    2398\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features_train_ord_downsampled, target_train_downsampled = downsample(features_train_ord, target_train, 0.5)\n",
    "features_train_ord_balanced, target_train_balanced = upsample(features_train_ord_downsampled, target_train_downsampled, 2)\n",
    "\n",
    "print(features_train_ord_balanced.shape)\n",
    "print(target_train_balanced.shape)\n",
    "print(target_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb2cb7a2-b4dc-402f-b31b-6625fbafece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.5482456140350878 obtained using max depth 4.\n",
      "Model accuracy: 0.794\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "model_accuracy = 0\n",
    "best_f1_score = 0\n",
    "model_tree = None\n",
    "\n",
    "for depth in range(1,11):\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state = 123) # create instance of class\n",
    "    model.fit(features_train_ord_balanced, target_train_balanced) # Fit model with training data\n",
    "    pred_valid = model.predict(features_valid_ord)\n",
    "    \n",
    "    f1_score_var = f1_score(target_valid, pred_valid) # Calculate f1 score\n",
    "    accuracy = accuracy_score(target_valid, pred_valid)\n",
    "\n",
    "    # Document the highest-performing hyperparamaters, along with their corresponding accuracy\n",
    "    if f1_score_var > best_f1_score: \n",
    "        best_f1_score = f1_score_var\n",
    "        model_accuracy = accuracy\n",
    "        best_depth = depth\n",
    "        model_tree = model\n",
    "        \n",
    "print(f'Best F1 score: {best_f1_score} obtained using max depth {best_depth}.') \n",
    "print(f'Model accuracy: {model_accuracy}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a04d6-a609-44dc-ba74-3771dff3f7db",
   "metadata": {},
   "source": [
    "The F1 score is a bit higher than it was before balancing classes, but still has not met the requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed604db-64db-445b-85a0-f94279d1d29a",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a340bfe-cdab-46b9-9a90-3d5a27dd65e4",
   "metadata": {},
   "source": [
    "Since the random forest model was the top-performing model in the previous section, I want to do my best to optimize this one. Instead of making the classes equal, I want to add loops into my model training that will upsample and downsample my data at different multipliers and fractions, in addition to looping through the number of estimators and the max depth. To keep the model performing at a reasonable speed, I will keep my number of estimators in a tighter range than I did previously, which hopefully will also help to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8bfab6-cfb9-4f45-9fdf-f4902f1afb6e",
   "metadata": {},
   "source": [
    "***Note to reviewer: here is the code block that might cause a jam - comment out this block, and remove the comment markers from the next cell block below if the code takes too long to run.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0e058d9-2c08-42cb-a185-b624089ad653",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1_score = 0\n",
    "model_accuracy = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "model_forest = None\n",
    "best_x = 0\n",
    "best_y = 0\n",
    "\n",
    "for x in range(5, 11): # Loop through downsampling fractions 0.5 to 1 (see downsample function call below)\n",
    "    for y in range(1, 4): # loop through upsample multipliers 1 to 3 (see upsample function call below)\n",
    "        for est in range (20, 51, 10):\n",
    "            for depth in range (1, 11):\n",
    "                \n",
    "                features_train_ord_downsampled, target_train_downsampled = downsample(features_train_ord, target_train, x/10)\n",
    "                features_train_ord_balanced, target_train_balanced = upsample(features_train_ord_downsampled, target_train_downsampled, y)\n",
    "                \n",
    "                model = RandomForestClassifier(\n",
    "                    max_features=1.0, # The lack of this hyperparameter was causing warnings.\n",
    "                    n_estimators=est, max_depth=depth, random_state=123)\n",
    "                model.fit(features_train_ord_balanced, target_train_balanced)\n",
    "                pred_valid = model.predict(features_valid_ord)\n",
    "\n",
    "                f1_score_var = f1_score(target_valid, pred_valid) # Calculate f1 score\n",
    "                accuracy = accuracy_score(target_valid, pred_valid)\n",
    "\n",
    "                if f1_score_var > best_f1_score: \n",
    "                    best_f1_score = f1_score_var\n",
    "                    model_accuracy = accuracy\n",
    "                    best_depth = depth\n",
    "                    best_est = est\n",
    "                    model_forest = model  \n",
    "                    best_x = x\n",
    "                    best_y = y\n",
    "            \n",
    "print(f\"Best F1 score: {best_f1_score} obtained using {best_est} trees with\\\n",
    " max_depth {best_depth}.\")\n",
    "print(f'Ideal class balance achieved using downsampling fraction {x/10} and upsampling multiplier {y}.')\n",
    "print(f'Model accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1702c22-6f48-48e7-b12a-4dae68481c28",
   "metadata": {},
   "source": [
    "The F1 score measured from the validation set is 0.61, which is above our 0.59 requirement! This score resulted from zero downsampling and 3x upsampling. Perhaps removing training data is not always ideal. \n",
    "Hyperparameters: 30 trees, max depth 9.\n",
    "With zero downsampling and 3x upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e89a2c04-757d-46cf-8469-c0651c76a46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.5909090909090909 obtained using 30 trees with max_depth 9.\n",
      "Ideal class balance achieved using downsampling fraction 1.0 and upsampling multiplier 3.\n",
      "Model accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "# features_train_ord_downsampled, target_train_downsampled = downsample(features_train_ord, target_train, 1)\n",
    "# features_train_ord_balanced, target_train_balanced = upsample(features_train_ord_downsampled, target_train_downsampled, 3)\n",
    "\n",
    "# model_forest = RandomForestClassifier(\n",
    "#     max_features=1.0, # The lack of this hyperparameter was causing warnings.\n",
    "#     n_estimators=30, max_depth=9, random_state=123)\n",
    "# model_forest.fit(features_train_ord_balanced, target_train_balanced)\n",
    "# pred_valid = model_forest.predict(features_valid_ord)\n",
    "\n",
    "# f1_score_var = f1_score(target_valid, pred_valid) # Calculate f1 score\n",
    "# accuracy = accuracy_score(target_valid, pred_valid)\n",
    "            \n",
    "# print(f\"Best F1 score: {f1_score_var} obtained using 30 trees with\\\n",
    "#  max_depth 9.\")\n",
    "# print(f'Ideal class balance achieved using downsampling fraction 1.0 and upsampling multiplier 3.')\n",
    "# print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9ba10-1639-4e8b-95eb-2460a5787d49",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4922c48-9122-41ca-9de7-8229f76c0a1c",
   "metadata": {},
   "source": [
    "Let's test our highest performing model, the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "905a1b31-050c-492f-b7a3-29d7cbf1ec7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for test set: 0.6313416009019166\n",
      "Accuracy for test set: 0.8365\n"
     ]
    }
   ],
   "source": [
    "pred_test = model_forest.predict(features_test_ord)\n",
    "f1_score_test = f1_score(target_test, pred_test)\n",
    "accuracy_test = accuracy_score(target_test, pred_test)\n",
    "\n",
    "print('F1 score for test set:', f1_score_test)\n",
    "print('Accuracy for test set:', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5023a1e5-cd6c-4f57-9256-27e685ded62f",
   "metadata": {},
   "source": [
    "Perfect, the F1 score is comfortably above our requirement of 0.59! And the accuracy is above our requirement of 0.80 as well, showing that our model performs better than guessing all zeroes. Let's check out the AUC-ROC score. It should at least be 0.5, which is the score that guessing would obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b8d75d7-390b-45ba-9b3c-e6acec7c41a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC score: 0.8657912531754299\n"
     ]
    }
   ],
   "source": [
    "probabilities_test = model_forest.predict_proba(features_test_ord)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0,1])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print(f\"AUC-ROC score: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e19209f-46d7-4194-ba4f-421d6ff818b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "The AUC-ROC score is well above 0.5, and the curve looks excellent. This model satisfies all requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04c3be05-bd89-4ad5-b1d2-e5a6fe098075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a joblib file for sharing\n",
    "# dump(model_forest, 'BetaBankChurnPredictor.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d0ad4-2fa8-4476-982a-9d458bcbe385",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada79d8-7f2d-4b92-9d99-4e6ec2b1b378",
   "metadata": {},
   "source": [
    "My goal was to build a classification model that could predict whether or not Beta Bank customers would churn in the near future. To accomplish this I processed the data by splitting it into features/targets, splitting those into training/validation/testing sets, and encoding/standardizing the features in ways appropriate to the models that I was training - one-hot encoding for logistic regression, and label encoding for decision tree and random forest. I eventually balanced the classes and found that the random forest model (with 30 trees, a max depth of 9, zero downsampling, and 3x upsampling) performed best in regards to F1 score. The requirement for F1 score was 0.59, and this model had a 0.64 F1 score when trained with the Intel extension for scikit-learn, and a 0.63 F1 score without this extension, along with accuracy and AUC-ROC scores that passed sanity checks. I saved the model as a .joblib file to my machine for safekeeping.\n",
    "\n",
    "Personally, I enjoyed figuring out when to use one-hot encoding vs label encoding, and thinking about how to standardize my numeric features. Balancing classes was trickier than I expected, but ultimately I was able to refine my F1 score from just barely reaching the requirement to comfortably surpassing it, by using methods that I didn't explicitly learn in the sprint (tweaking the levels of upsampling and downsampling) which I found satisfying. I also have never tested the efficacy of the Intel performance-enhancing package before, and am seriously impressed by both its increased accuracy and speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cfb4c54-cffd-461c-9ff4-2cb98b88e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  57.575938\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
